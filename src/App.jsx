/**
 * D-Lab Flow ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨
 *
 * ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ YOLOv5 ëª¨ë¸ë¡œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
 * ë¸Œë¼ìš°ì €ì—ì„œ ì™„ì „íˆ ë™ì‘í•˜ë©° ì‚¬ìš©ìì˜ ì¹´ë©”ë¼ë¥¼ í†µí•´ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ë°”ìš´ë”© ë°•ìŠ¤ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
 */
import { useState, useRef, useEffect, useCallback } from 'react'
import Webcam from 'react-webcam'
import * as ort from 'onnxruntime-web'
import './App.css'

// ì „ì—­ ë³€ìˆ˜ë¡œ ì •ì˜ (ìµœì†Œê°’ 0.4ë¡œ ì„¤ì •)
let confidenceThreshold = 0.4;

function App() {
  // Refs
  const webcamRef = useRef(null);
  const canvasRef = useRef(null);
  const sessionRef = useRef(null);
  const animationRef = useRef(null);
  const streamRef = useRef(null);
  const scaleCanvasRef = useRef(document.createElement('canvas'));

  const detectionMemoryRef = useRef([]); // ìµœì‹  íƒì§€ ê²°ê³¼ + ìœ ì§€í•  ì´ì „ ê²°ê³¼ í¬í•¨
  const MAX_MISSED_FRAMES = 3; // ê°ì²´ê°€ ì•ˆ ë³´ì—¬ë„ ëª‡ í”„ë ˆì„ ìœ ì§€

  // State variables
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [isModelLoading, setIsModelLoading] = useState(true);
  const [classes, setClasses] = useState([]);
  const [isDetecting, setIsDetecting] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  const [detections, setDetections] = useState([]);
  const [debugMode] = useState(true); // ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”
  
  // ëª¨ë¸ ì¶œë ¥ êµ¬ì¡° ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ref ì¶”ê°€
  const modelInfoRef = useRef({
    outputShape: null,
    detectionLength: 85, // ê¸°ë³¸ê°’ (YOLOv5s)
    numClasses: 80,
    isYOLOv5su: false,
    coordinateFormat: 'center', // 'center' or 'corner'
    numDetections: null,
    isTransposed: false
  });

  // ëª¨ë¸ ë¡œë“œ
  useEffect(() => {
    console.log('ğŸ”¥ NEW CODE LOADED - ìƒˆë¡œìš´ ì½”ë“œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!'); // ê°•ì œ í™•ì¸ìš©
    async function loadModel() {
      try {
        setIsModelLoading(true);
        const res = await fetch('/models/classes.json');
        setClasses(await res.json());
        const session = await ort.InferenceSession.create('/models/model.onnx', {
          executionProviders: ['webgpu', 'webgl', 'cpu'],
          graphOptimizationLevel: 'all',
          enableCpuMemArena: false,
          enableMemPattern: false,
        });
        sessionRef.current = session;
        
        // ëª¨ë¸ì˜ ì¶œë ¥ êµ¬ì¡° ì •ë³´ í™•ì¸
        const outputNames = session.outputNames;
        console.log('ğŸš€ Model output names:', outputNames);
        
        // í…ŒìŠ¤íŠ¸ ì¶”ë¡ ì„ í†µí•´ ì¶œë ¥ êµ¬ì¡° í™•ì¸
        await detectModelStructure(session);
        
        setIsModelLoaded(true);
      } catch (e) {
        console.error('Error loading model:', e);
        setErrorMessage('ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜. public/models ë””ë ‰í† ë¦¬ì— model.onnx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.');
      } finally {
        setIsModelLoading(false);
      }
    }
    loadModel();
    return () => {
      if (animationRef.current) cancelAnimationFrame(animationRef.current);
      if (streamRef.current) streamRef.current.getTracks().forEach(t => t.stop());
    };
  }, []);

  // ëª¨ë¸ ì¶œë ¥ êµ¬ì¡°ë¥¼ ê°ì§€í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
  const detectModelStructure = async (session) => {
    try {
      console.log('ğŸ” ëª¨ë¸ êµ¬ì¡° ê°ì§€ ì‹œì‘...');
      // ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ìˆ˜í–‰
      const dummyInput = new Float32Array(640 * 640 * 3).fill(0.5);
      const tensor = new ort.Tensor('float32', dummyInput, [1, 3, 640, 640]);
      const results = await session.run({ images: tensor });
      
      const outputKey = Object.keys(results)[0];
      const output = results[outputKey];
      const dims = output.dims;
      
      console.log('ğŸ¯ Model output dimensions:', dims);
      console.log('ğŸ“Š Sample output data (first 20 values):', Array.from(output.data.slice(0, 20)));
      
      // ì¶œë ¥ êµ¬ì¡° ë¶„ì„
      if (dims.length === 3) {
        const [batch, dim1, dim2] = dims;
        modelInfoRef.current.outputShape = dims;
        
        // YOLOv5suëŠ” ì¢…ì¢… transposeëœ í˜•íƒœë¡œ ì¶œë ¥ë¨: [1, 84, 8400] vs [1, 8400, 84]
        let numDetections, detectionLength;
        let isTransposed = false;
        
        // ì¼ë°˜ì ìœ¼ë¡œ detection ê°œìˆ˜ê°€ feature ê°œìˆ˜ë³´ë‹¤ í›¨ì”¬ ë§ìŒ (8400 vs 84/85)
        if (dim2 > dim1) {
          // transposeëœ í˜•íƒœ: [1, 84/85/6, 8400]
          numDetections = dim2;
          detectionLength = dim1;
          isTransposed = true;
        } else {
          // ì¼ë°˜ì ì¸ í˜•íƒœ: [1, 8400, 84/85/6]
          numDetections = dim1;
          detectionLength = dim2;
          isTransposed = false;
        }
        
        modelInfoRef.current.detectionLength = detectionLength;
        modelInfoRef.current.numDetections = numDetections;
        modelInfoRef.current.isTransposed = isTransposed;
        
        console.log(`ğŸ”„ Transpose ê°ì§€: ${isTransposed ? 'YES' : 'NO'}`);
        console.log(`ğŸ“ Detection length: ${detectionLength}, Num detections: ${numDetections}`);
        
        // ì¶œë ¥ í˜•íƒœë³„ ì²˜ë¦¬
        if (detectionLength === 6) {
          // YOLOv5su corner format: [x1, y1, x2, y2, confidence, class_id]
          modelInfoRef.current.isYOLOv5su = true;
          modelInfoRef.current.numClasses = classes.length || 80;
          modelInfoRef.current.coordinateFormat = 'corner';
          console.log('âœ… YOLOv5su í˜•íƒœ ëª¨ë¸ ê°ì§€ë¨ (6ê°œ ê°’ ì¶œë ¥ - corner format)');
        } else if (detectionLength === 85) {
          // YOLOv5s í˜•íƒœ: [cx, cy, w, h, objectness, class1, ..., class80]
          modelInfoRef.current.isYOLOv5su = false;
          modelInfoRef.current.numClasses = 80;
          modelInfoRef.current.coordinateFormat = 'center';
          console.log('âœ… YOLOv5s í˜•íƒœ ëª¨ë¸ ê°ì§€ë¨ (85ê°œ ê°’ ì¶œë ¥ - center format)');
        } else if (detectionLength === 84) {
          // YOLOv5su center format: [cx, cy, w, h, class1, ..., class80] (objectness ì—†ìŒ)
          modelInfoRef.current.isYOLOv5su = true;
          modelInfoRef.current.numClasses = 80;
          modelInfoRef.current.coordinateFormat = 'center';
          console.log('âœ… YOLOv5su í˜•íƒœ ëª¨ë¸ ê°ì§€ë¨ (84ê°œ ê°’ ì¶œë ¥ - center format, no objectness)');
        } else {
          // ë‹¤ë¥¸ êµ¬ì¡°ì˜ ê²½ìš°
          const possibleNumClasses = detectionLength - 5;
          modelInfoRef.current.numClasses = Math.max(possibleNumClasses, 1);
          modelInfoRef.current.coordinateFormat = detectionLength <= 10 ? 'corner' : 'center';
          console.log(`âœ… ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ê°ì§€ë¨ (${detectionLength}ê°œ ê°’, ${modelInfoRef.current.numClasses}ê°œ í´ë˜ìŠ¤)`);
        }
      }
      
      console.log('ğŸ“‹ Model structure detected:', modelInfoRef.current);
    } catch (error) {
      console.warn('âš ï¸ ëª¨ë¸ êµ¬ì¡° ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', error);
      // ê¸°ë³¸ê°’ ìœ ì§€
    }
  };

  // ë Œë”ë§ ë£¨í”„
  const drawLoop = useCallback(() => {
    const canvas = canvasRef.current;
    const video = webcamRef.current?.video;
    if (!canvas || !video) return;
    // ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ë¹„ë””ì˜¤ í•´ìƒë„ì— ë§ì¶¤
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    // ê·¸ë¦¬ê¸° ì „ í´ë¦¬ì–´
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    drawBoundingBoxes(detectionMemoryRef.current, ctx, canvas.width, canvas.height);
    animationRef.current = requestAnimationFrame(drawLoop);
  }, []);

  // ì¶”ë¡  ë£¨í”„
  const inferenceLoop = useCallback(async () => {
    if (!isDetecting || !webcamRef.current || !sessionRef.current) return;
    const video = webcamRef.current.video;
    if (video.readyState === 4) {
      const scaleCanvas = scaleCanvasRef.current;
      const factor = 0.5;
      scaleCanvas.width = Math.floor(video.videoWidth * factor);
      scaleCanvas.height = Math.floor(video.videoHeight * factor);
      const sctx = scaleCanvas.getContext('2d');
      sctx.drawImage(video, 0, 0, scaleCanvas.width, scaleCanvas.height);
      const imageData = sctx.getImageData(0, 0, scaleCanvas.width, scaleCanvas.height);
      const [input, iw, ih] = await prepareInput(imageData);
      const results = await sessionRef.current.run({ images: input });
      const out = results[Object.keys(results)[0]];
      
      // ëª¨ë¸ ì¶œë ¥ ì •ë³´ ë¡œê·¸ ì¶”ê°€ ë° ì‹¤ì‹œê°„ transpose ê°ì§€
      if (debugMode) {
        console.log('=== ì¶”ë¡  ê²°ê³¼ ===');
        console.log('Output dimensions:', out.dims);
        console.log('Sample raw data (first 12 values):', Array.from(out.data.slice(0, 12)));
        
        // ğŸ¯ ì‹¤ì‹œê°„ ëª¨ë¸ êµ¬ì¡° ìë™ ê°ì§€ (YOLOv5s/YOLOv5su ëª¨ë“  í˜•íƒœ ì§€ì›)
        if (out.dims.length === 3) {
          const [batch, dim1, dim2] = out.dims;
          let numDetections, detectionLength, isTransposed;
          
          // transpose ì—¬ë¶€ ê²°ì • (detection ê°œìˆ˜ê°€ feature ê°œìˆ˜ë³´ë‹¤ í›¨ì”¬ ë§ìŒ)
          if (dim2 > dim1) {
            // transposeëœ í˜•íƒœ: [1, N, 8400]
            isTransposed = true;
            numDetections = dim2;
            detectionLength = dim1;
          } else {
            // ì¼ë°˜ì ì¸ í˜•íƒœ: [1, 8400, N]
            isTransposed = false;
            numDetections = dim1;
            detectionLength = dim2;
          }
          
          // ëª¨ë¸ ì •ë³´ ì—…ë°ì´íŠ¸
          modelInfoRef.current.isTransposed = isTransposed;
          modelInfoRef.current.numDetections = numDetections;
          modelInfoRef.current.detectionLength = detectionLength;
          
          // ğŸ” ëª¨ë¸ íƒ€ì… ìë™ ê°ì§€
          let modelType = "Unknown";
          let coordinateFormat = "center";
          let isYOLOv5su = false;
          let numClasses = 80;
          
          if (detectionLength === 85) {
            // YOLOv5s: [cx, cy, w, h, objectness, class1, ..., class80]
            modelType = "YOLOv5s";
            coordinateFormat = "center";
            isYOLOv5su = false;
            numClasses = 80;
          } else if (detectionLength === 84) {
            // YOLOv5su Center: [cx, cy, w, h, class1, ..., class80] (objectness ì—†ìŒ)
            modelType = "YOLOv5su (Center)";
            coordinateFormat = "center";
            isYOLOv5su = true;
            numClasses = 80;
          } else if (detectionLength === 6) {
            // YOLOv5su Corner: [x1, y1, x2, y2, confidence, class_id]
            modelType = "YOLOv5su (Corner)";
            coordinateFormat = "corner";
            isYOLOv5su = true;
            numClasses = classes.length || 80;
          } else if (detectionLength > 6) {
            // ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ (ì¶”ì •)
            const possibleClasses = detectionLength - 5; // objectness + 4ê°œ ì¢Œí‘œ
            if (possibleClasses > 0) {
              modelType = `Custom YOLO (${possibleClasses} classes)`;
              coordinateFormat = "center";
              isYOLOv5su = false;
              numClasses = possibleClasses;
            } else {
              modelType = `Custom YOLO (${detectionLength} features)`;
              coordinateFormat = detectionLength <= 10 ? "corner" : "center";
              isYOLOv5su = true;
              numClasses = Math.max(1, detectionLength - 4);
            }
          }
          
          // ì„¤ì • ì ìš©
          modelInfoRef.current.isYOLOv5su = isYOLOv5su;
          modelInfoRef.current.coordinateFormat = coordinateFormat;
          modelInfoRef.current.numClasses = numClasses;
          
          console.log(`ğŸ¯ ìë™ ê°ì§€ ì™„ë£Œ: ${modelType}`);
          console.log(`ğŸ“ í˜•íƒœ: ${isTransposed ? 'Transpose' : 'Normal'} [${batch}, ${dim1}, ${dim2}]`);
          console.log(`ğŸ“Š Features: ${detectionLength}, Detections: ${numDetections}, Classes: ${numClasses}`);
          console.log(`ğŸ“ ì¢Œí‘œ í˜•ì‹: ${coordinateFormat}, YOLOv5su: ${isYOLOv5su}`);
        }
        
        console.log('Model info (updated):', modelInfoRef.current);
      }
      
      const newDetections = processDetections(
          out.data,
          out.dims,
          iw,
          ih,
          video.videoWidth,
          video.videoHeight
      );
      if (newDetections.length > 0) {
        detectionMemoryRef.current = newDetections.map(d => ({ ...d, missed: 0 }));
      } else {
        detectionMemoryRef.current = detectionMemoryRef.current
            .map(d => ({ ...d, missed: d.missed + 1 }))
            .filter(d => d.missed <= MAX_MISSED_FRAMES);
      }
      setDetections(detectionMemoryRef.current);
    }
    setTimeout(inferenceLoop, 10);
  }, [isDetecting]);

  // isDetecting ë³€ê²½ì‹œ ë£¨í”„ ì‹œì‘/ì¤‘ì§€
  useEffect(() => {
    if (isDetecting) {
      requestAnimationFrame(drawLoop);
      inferenceLoop();
    } else {
      if (animationRef.current) cancelAnimationFrame(animationRef.current);
    }
  }, [isDetecting, drawLoop, inferenceLoop]);

  // ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = () => {
    console.log('ğŸ“¹ ì¹´ë©”ë¼ ì‹œì‘ - ìƒˆë¡œìš´ ë””ë²„ê¹… ì½”ë“œ í™œì„±í™”ë¨!'); // ê°•ì œ í™•ì¸ìš©
    setIsDetecting(true);
  };

  // ì¹´ë©”ë¼ ì¤‘ì§€
  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(t => t.stop());
      streamRef.current = null;
    }
    setIsDetecting(false);
    setDetections([]);
  };

    // Process detections from model output - ìˆ˜ì •ëœ ë²„ì „
  const processDetections = (data, dims, imgWidth, imgHeight, canvasWidth, canvasHeight) => {
    const detectionLength = modelInfoRef.current.detectionLength;
    const numDetections = modelInfoRef.current.numDetections || dims[1];
    const isYOLOv5su = modelInfoRef.current.isYOLOv5su;
    const coordinateFormat = modelInfoRef.current.coordinateFormat;
    const isTransposed = modelInfoRef.current.isTransposed || false;

    // ëª¨ë¸ ì…ë ¥ í¬ê¸° (YOLOv5ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 640x640 ì…ë ¥ì„ ì‚¬ìš©)
    const modelWidth = 640;
    const modelHeight = 640;

    if (debugMode) {
      console.log(`=== Detection Processing ===`);
      console.log(`Canvas: ${canvasWidth}x${canvasHeight}, Model: ${modelWidth}x${modelHeight}`);
      console.log(`Model type: ${isYOLOv5su ? 'YOLOv5su' : 'YOLOv5s'}, Coordinate format: ${coordinateFormat}`);
      console.log(`Detection length: ${detectionLength}, Num detections: ${numDetections}`);
      console.log(`Output dimensions: [${dims.join(', ')}], Transposed: ${isTransposed}`);
    }

    const rawDetections = [];
    const classDetections = {};

    // transposeëœ ë°ì´í„°ì—ì„œ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜
    const getValue = (detectionIndex, valueIndex) => {
      if (isTransposed) {
        // [1, 84, 8400] í˜•íƒœì—ì„œ: data[valueIndex * numDetections + detectionIndex]
        return data[valueIndex * numDetections + detectionIndex];
      } else {
        // [1, 8400, 84] í˜•íƒœì—ì„œ: data[detectionIndex * detectionLength + valueIndex]
        return data[detectionIndex * detectionLength + valueIndex];
      }
    };

    for (let i = 0; i < numDetections; i++) {
      let bbox, confidence, classIndex, className;

      if (isYOLOv5su) {
        if (coordinateFormat === 'corner' && detectionLength === 6) {
          // YOLOv5su corner format: [x1, y1, x2, y2, confidence, class_id]
          let x1 = getValue(i, 0);
          let y1 = getValue(i, 1);
          let x2 = getValue(i, 2);
          let y2 = getValue(i, 3);
          confidence = getValue(i, 4);
          classIndex = Math.round(getValue(i, 5));
          
          // confidence ê°’ì´ sigmoidë¥¼ ê±°ì³ì•¼ í•˜ëŠ”ì§€ í™•ì¸
          if (confidence > 1) {
            confidence = 1 / (1 + Math.exp(-confidence));
          }
          
          if (debugMode && i < 3) {
            console.log(`Raw detection ${i}: [${x1.toFixed(4)}, ${y1.toFixed(4)}, ${x2.toFixed(4)}, ${y2.toFixed(4)}, ${confidence.toFixed(4)}, ${classIndex}]`);
          }
          
          // ì¢Œí‘œê°€ 0-1 ë²”ìœ„ì¸ì§€ í™•ì¸ (ì •ê·œí™”ëœ ì¢Œí‘œ)
          if (x1 <= 1 && y1 <= 1 && x2 <= 1 && y2 <= 1 && x1 >= 0 && y1 >= 0 && x2 >= 0 && y2 >= 0) {
            // ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ìº”ë²„ìŠ¤ í¬ê¸°ë¡œ ë³€í™˜
            x1 *= canvasWidth;
            y1 *= canvasHeight;
            x2 *= canvasWidth;
            y2 *= canvasHeight;
          } else {
            // ì´ë¯¸ í”½ì…€ ì¢Œí‘œì¸ ê²½ìš° ëª¨ë¸ í¬ê¸°ì—ì„œ ìº”ë²„ìŠ¤ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
            const scaleX = canvasWidth / modelWidth;
            const scaleY = canvasHeight / modelHeight;
            x1 *= scaleX;
            y1 *= scaleY;
            x2 *= scaleX;
            y2 *= scaleY;
          }
          
          // x1,y1,x2,y2ë¥¼ x,y,width,height í˜•íƒœë¡œ ë³€í™˜
          const x = Math.min(x1, x2);
          const y = Math.min(y1, y2);
          const width = Math.abs(x2 - x1);
          const height = Math.abs(y2 - y1);
          
          // ìœ íš¨ì„± ê²€ì‚¬ - ë„ˆë¬´ ì‘ê±°ë‚˜ í™”ë©´ ë°–ì˜ ë°•ìŠ¤ ì œê±°
          if (width < 5 || height < 5 || x < -canvasWidth || y < -canvasHeight || 
              x > canvasWidth * 2 || y > canvasHeight * 2) {
            if (debugMode && i < 3) {
              console.log(`Invalid bbox rejected: [${x.toFixed(2)}, ${y.toFixed(2)}, ${width.toFixed(2)}, ${height.toFixed(2)}]`);
            }
            continue;
          }
          
          bbox = [x, y, width, height];
          className = classes[classIndex] || `í´ë˜ìŠ¤ ${classIndex}`;
          
        } else if (coordinateFormat === 'center') {
          // YOLOv5su center format: [cx, cy, w, h, class1, ..., classN] (84ê°œ)
          let cx = getValue(i, 0);
          let cy = getValue(i, 1);
          let width = getValue(i, 2);
          let height = getValue(i, 3);
          
          // í´ë˜ìŠ¤ í™•ë¥  ê³„ì‚° (objectness ì—†ìŒ)
          let maxClassProb = 0;
          classIndex = 0;
          const numClasses = modelInfoRef.current.numClasses;
          
          for (let j = 4; j < Math.min(4 + numClasses, detectionLength); j++) {
            const prob = getValue(i, j);
            // ì´ë¯¸ sigmoidê°€ ì ìš©ëœ ê°’ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            const finalProb = prob > 1 ? (1 / (1 + Math.exp(-prob))) : prob;
            if (finalProb > maxClassProb) {
              maxClassProb = finalProb;
              classIndex = j - 4;
            }
          }
          
          confidence = maxClassProb;
          className = classes[classIndex] || `í´ë˜ìŠ¤ ${classIndex}`;
          
          if (debugMode && i < 3) {
            console.log(`Raw center detection ${i}: [${cx.toFixed(4)}, ${cy.toFixed(4)}, ${width.toFixed(4)}, ${height.toFixed(4)}], conf=${confidence.toFixed(4)}, class=${classIndex}`);
          }
          
          // ì¢Œí‘œ ë³€í™˜ (ì •ê·œí™” ì—¬ë¶€ í™•ì¸)
          if (cx <= 1 && cy <= 1 && width <= 1 && height <= 1 && cx >= 0 && cy >= 0) {
            // ì •ê·œí™”ëœ ì¢Œí‘œ
            cx *= canvasWidth;
            cy *= canvasHeight;
            width *= canvasWidth;
            height *= canvasHeight;
          } else {
            // í”½ì…€ ì¢Œí‘œ
            const scaleX = canvasWidth / modelWidth;
            const scaleY = canvasHeight / modelHeight;
            cx *= scaleX;
            cy *= scaleY;
            width *= scaleX;
            height *= scaleY;
          }
          
          const x = cx - width/2;
          const y = cy - height/2;
          
          // ìœ íš¨ì„± ê²€ì‚¬
          if (width < 5 || height < 5 || x < -canvasWidth || y < -canvasHeight || 
              x > canvasWidth * 2 || y > canvasHeight * 2) {
            if (debugMode && i < 3) {
              console.log(`Invalid center bbox rejected: [${x.toFixed(2)}, ${y.toFixed(2)}, ${width.toFixed(2)}, ${height.toFixed(2)}]`);
            }
            continue;
          }
          
          bbox = [x, y, width, height];
          
          if (debugMode && i < 3) {
            console.log(`Processed center detection ${i}: bbox=[${x.toFixed(2)}, ${y.toFixed(2)}, ${width.toFixed(2)}, ${height.toFixed(2)}], conf=${confidence.toFixed(3)}, class=${classIndex}(${className})`);
          }
        }
        
      } else {
        // YOLOv5s í˜•íƒœ: [cx, cy, w, h, objectness, class1, ..., class80]
        const objectness = 1 / (1 + Math.exp(-getValue(i, 4)));
        let maxClassProb = 0;
        classIndex = 0;
        
        const numClasses = modelInfoRef.current.numClasses;
        for (let j = 5; j < 5 + numClasses; j++) {
          const prob = 1 / (1 + Math.exp(-getValue(i, j)));
          if (prob > maxClassProb) {
            maxClassProb = prob;
            classIndex = j - 5;
          }
        }
        
        confidence = objectness * maxClassProb;
        className = classes[classIndex] || `í´ë˜ìŠ¤ ${classIndex}`;

        // Extract bounding box coordinates (center formatì„ corner formatìœ¼ë¡œ ë³€í™˜)
        const scaleX = canvasWidth / modelWidth;
        const scaleY = canvasHeight / modelHeight;
        const cx = getValue(i, 0) * scaleX;
        const cy = getValue(i, 1) * scaleY;
        const width = getValue(i, 2) * scaleX;
        const height = getValue(i, 3) * scaleY;
        
        bbox = [cx - width/2, cy - height/2, width, height];
      }

      // Filter by confidence threshold
      if (confidence > confidenceThreshold) {
        // Track detections by class
        if (!classDetections[className]) {
          classDetections[className] = {
            count: 0,
            confidenceSum: 0,
            highestConfidence: 0
          };
        }
        classDetections[className].count++;
        classDetections[className].confidenceSum += confidence;
        classDetections[className].highestConfidence = Math.max(classDetections[className].highestConfidence, confidence);

        // Log individual detection with high confidence (only in debug mode)
        if (debugMode && rawDetections.length < 5) {
          console.log(`íƒì§€ëœ ê°ì²´: ${className}, ì¸ì‹ë¥ : ${(confidence * 100).toFixed(2)}%, ìœ„ì¹˜: [x=${Math.round(bbox[0])}, y=${Math.round(bbox[1])}, w=${Math.round(bbox[2])}, h=${Math.round(bbox[3])}]`);
        }

        rawDetections.push({
          bbox: bbox,
          class: className,
          confidence: confidence,
          classIndex: classIndex
        });
      }
    }

    // Apply Non-Maximum Suppression to filter out overlapping detections
    const detections = applyNonMaxSuppression(rawDetections, 0.3); // 0.3 is the IoU threshold (lower value = more aggressive filtering)

    // ì¶”ë¡  ê²°ê³¼ ìš”ì•½ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ)
    if (debugMode) {
      if (Object.keys(classDetections).length > 0) {
        console.log('======== ì¶”ë¡  ê²°ê³¼ ìš”ì•½ ========');
        console.log(`ì´ íƒì§€ëœ ê°ì²´ ìˆ˜: ${rawDetections.length}ê°œ (NMS ì ìš© ì „), ${detections.length}ê°œ (NMS ì ìš© í›„)`);

        // í´ë˜ìŠ¤ë³„ íƒì§€ ê²°ê³¼ ë° ì¸ì‹ë¥  ì¶œë ¥
        Object.keys(classDetections).forEach(className => {
          const stats = classDetections[className];
          const avgConfidence = stats.confidenceSum / stats.count;
          console.log(`í´ë˜ìŠ¤: ${className}, íƒì§€ ìˆ˜: ${stats.count}ê°œ, í‰ê·  ì¸ì‹ë¥ : ${(avgConfidence * 100).toFixed(2)}%, ìµœê³  ì¸ì‹ë¥ : ${(stats.highestConfidence * 100).toFixed(2)}%`);
        });
        console.log('===============================');
      } else {
        console.log('íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.');
      }
    }

    return detections;
  };

  // Calculate Intersection over Union (IoU) between two bounding boxes
  const calculateIoU = (box1, box2) => {
    // box format: [x, y, width, height] where x,y is the top-left corner
    const [x1, y1, w1, h1] = box1;
    const [x2, y2, w2, h2] = box2;

    // Calculate coordinates of the intersection rectangle
    const xLeft = Math.max(x1, x2);
    const yTop = Math.max(y1, y2);
    const xRight = Math.min(x1 + w1, x2 + w2);
    const yBottom = Math.min(y1 + h1, y2 + h2);

    // Check if there is an intersection
    if (xRight < xLeft || yBottom < yTop) {
      return 0;
    }

    // Calculate intersection area
    const intersectionArea = (xRight - xLeft) * (yBottom - yTop);

    // Calculate union area
    const box1Area = w1 * h1;
    const box2Area = w2 * h2;
    const unionArea = box1Area + box2Area - intersectionArea;

    // Calculate IoU
    return intersectionArea / unionArea;
  };

  // Apply Non-Maximum Suppression to filter out overlapping detections
  const applyNonMaxSuppression = (detections, iouThreshold) => {
    if (detections.length === 0) {
      return [];
    }

    // Sort detections by confidence score (highest first)
    const sortedDetections = [...detections].sort((a, b) => b.confidence - a.confidence);

    const selectedDetections = [];
    const remainingDetections = [...sortedDetections];

    // Process all detections
    while (remainingDetections.length > 0) {
      // Select the detection with highest confidence
      const currentDetection = remainingDetections.shift();
      selectedDetections.push(currentDetection);

      // Filter out detections that have high overlap with the current detection
      // and are of the same class
      let i = 0;
      while (i < remainingDetections.length) {
        // Only apply NMS to detections of the same class
        if (remainingDetections[i].classIndex === currentDetection.classIndex) {
          const iou = calculateIoU(currentDetection.bbox, remainingDetections[i].bbox);

          // If IoU is above threshold, remove this detection
          if (iou > iouThreshold) {
            remainingDetections.splice(i, 1);
          } else {
            i++;
          }
        } else {
          i++;
        }
      }
    }

    return selectedDetections;
  };

  // Prepare input tensor for the model
  const prepareInput = async (imageData) => {
    // YOLOv5 expects input in format [batch, channels, height, width]
    const imgWidth = imageData.width;
    const imgHeight = imageData.height;

    // YOLOv5 models typically expect 640x640 input
    const modelWidth = 640;
    const modelHeight = 640;

    // Create a temporary canvas for the source image data
    const sourceCanvas = document.createElement('canvas');
    sourceCanvas.width = imgWidth;
    sourceCanvas.height = imgHeight;
    const sourceCtx = sourceCanvas.getContext('2d');
    sourceCtx.putImageData(imageData, 0, 0);

    // Create a temporary canvas for resizing
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = modelWidth;
    tempCanvas.height = modelHeight;
    const tempCtx = tempCanvas.getContext('2d');

    // Draw and resize the image
    tempCtx.drawImage(
        sourceCanvas,
        0, 0, imgWidth, imgHeight,
        0, 0, modelWidth, modelHeight
    );

    // Get the resized image data
    const resizedImageData = tempCtx.getImageData(0, 0, modelWidth, modelHeight);
    const pixels = resizedImageData.data;

    // Prepare the input tensor (NCHW format)
    // YOLOv5 expects RGB values normalized to [0, 1]
    const inputTensor = new Float32Array(modelWidth * modelHeight * 3);
    let inputIndex = 0;

    // Convert from RGBA to RGB and normalize
    for (let c = 0; c < 3; c++) {
      for (let h = 0; h < modelHeight; h++) {
        for (let w = 0; w < modelWidth; w++) {
          const pixelIndex = (h * modelWidth + w) * 4; // RGBA has 4 channels
          inputTensor[inputIndex++] = pixels[pixelIndex + c] / 255.0;
        }
      }
    }

    // Create the ONNX tensor
    const tensor = new ort.Tensor('float32', inputTensor, [1, 3, modelHeight, modelWidth]);

    return [tensor, imgWidth, imgHeight];
  };

  // Draw bounding boxes on the canvas
  const drawBoundingBoxes = (detections, ctx, canvasWidth, canvasHeight) => {
    try {
      // ìº”ë²„ìŠ¤ ìƒíƒœ ì €ì¥
      ctx.save();

      // ê¸°ë³¸ ìº”ë²„ìŠ¤ ì„¤ì • (ëª¨ë°”ì¼ í˜¸í™˜ì„± ìœ„í•´ ê°„ì†Œí™”)
      ctx.imageSmoothingEnabled = true;
      ctx.imageSmoothingQuality = 'medium'; // highì—ì„œ mediumìœ¼ë¡œ ì¡°ì •

      if (detections.length > 0) {
        ctx.clearRect(0, 0, canvasWidth, canvasHeight);
      }

      // ëª¨ë“  íƒì§€ëœ ê°ì²´ ì‚¬ìš© (í•„í„°ë§ ì—†ìŒ)
      const recentDetections = detections;

      // ë¹„ë””ì˜¤ í”„ë ˆì„ì€ ë” ì´ìƒ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ì§€ ì•ŠìŒ (Webcam ì»´í¬ë„ŒíŠ¸ê°€ ë°°ê²½ìœ¼ë¡œ í‘œì‹œë¨)
      if (debugMode && webcamRef.current && webcamRef.current.video) {
        const video = webcamRef.current.video;
        if (video.readyState === 4) {
          // Log video dimensions only in debug mode
          console.log(`Video dimensions: ${video.videoWidth}x${video.videoHeight}`);
        }
      }

      if (debugMode) {
        console.log(`Drawing ${recentDetections.length} bounding boxes - Canvas dimensions: ${canvasWidth}x${canvasHeight}`);
      }

      // ìµœì¢… í™”ë©´ì— í‘œì‹œë˜ëŠ” íƒì§€ ê²°ê³¼ ìš”ì•½ (ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ)
      if (debugMode && recentDetections.length > 0) {
        console.log('======== í™”ë©´ í‘œì‹œ íƒì§€ ê²°ê³¼ ========');
        // í´ë˜ìŠ¤ë³„ í†µê³„ ê³„ì‚°ì„ ìœ„í•œ ê°ì²´
        const finalClassStats = {};

        recentDetections.forEach(detection => {
          const className = detection.class;
          if (!finalClassStats[className]) {
            finalClassStats[className] = {
              count: 0,
              confidenceSum: 0
            };
          }
          finalClassStats[className].count++;
          finalClassStats[className].confidenceSum += detection.confidence;
        });

        // í´ë˜ìŠ¤ë³„ í†µê³„ ì¶œë ¥
        Object.keys(finalClassStats).forEach(className => {
          const stats = finalClassStats[className];
          const avgConfidence = stats.confidenceSum / stats.count;
          console.log(`í´ë˜ìŠ¤: ${className}, ê°œìˆ˜: ${stats.count}ê°œ, í‰ê·  ì¸ì‹ë¥ : ${(avgConfidence * 100).toFixed(2)}%`);
        });
        console.log('==================================');
      }

      // Set drawing styles
      ctx.lineWidth = 1; // Reduced line width as requested
      ctx.font = 'bold 18px Arial'; // Made font bold for better visibility
      ctx.textBaseline = 'top';

      // Draw each filtered detection
      recentDetections.forEach((detection, i) => {
        const [drawX, drawY, width, height] = detection.bbox;
        const className = detection.class;
        const confidence = detection.confidence;
        const classIndex = detection.classIndex;

        // Log the detection information with more details in Korean (only in debug mode)
        if (debugMode) {
          console.log(`ìµœì¢… íƒì§€ #${i+1}: í´ë˜ìŠ¤=${className}, ì¸ì‹ë¥ =${(confidence * 100).toFixed(2)}%, ìœ„ì¹˜=[x=${Math.round(drawX)}, y=${Math.round(drawY)}, ë„ˆë¹„=${Math.round(width)}, ë†’ì´=${Math.round(height)}]`);
        }

        // Generate random color based on class index
        const hue = (classIndex * 137) % 360; // Use prime number for better distribution

        // ë” ì–‡ì€ í…Œë‘ë¦¬ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        ctx.strokeStyle = `hsl(${hue}, 100%, 50%)`;
        ctx.lineWidth = 1;

        // Draw bounding box with more visible style
        ctx.beginPath();
        ctx.rect(drawX, drawY, width, height);
        ctx.stroke();

        // ë¼ë²¨ ë°°ê²½ë„ ì•½ê°„ íˆ¬ëª…í•˜ê²Œ ì¡°ì •
        const label = `${className} ${Math.round(confidence * 100)}%`;
        const textMetrics = ctx.measureText(label);
        const textHeight = 28; // ë¼ë²¨ ë†’ì´ ìœ ì§€
        ctx.fillStyle = `hsla(${hue}, 100%, 50%, 0.7)`; // ì•½ê°„ íˆ¬ëª…í•˜ê²Œ ì¡°ì •

        // Calculate label position
        const labelX = drawX;
        const labelY = drawY - textHeight;

        ctx.fillRect(
            labelX,
            labelY,
            textMetrics.width + 10,
            textHeight
        );

        // ëª¨ë°”ì¼ì—ì„œ ë” ì˜ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
        // í…ìŠ¤íŠ¸ì— ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€
        ctx.shadowColor = 'black';
        ctx.shadowBlur = 3;
        ctx.shadowOffsetX = 1;
        ctx.shadowOffsetY = 1;

        // í°ìƒ‰ êµµì€ í…ìŠ¤íŠ¸
        ctx.fillStyle = 'white';
        ctx.font = 'bold 18px Arial'; // êµµì€ ê¸€ì”¨ì²´
        ctx.fillText(
            label,
            labelX + 5,
            labelY + 5
        );

        // ê·¸ë¦¼ì íš¨ê³¼ ì œê±°
        ctx.shadowColor = 'transparent';
      });

      // Restore the canvas state
      ctx.restore();

    } catch (error) {
      console.error("Error in drawBoundingBoxes:", error);
    }
  };

  // Inline UI components
  const Card = ({ className, children }) => (
      <div className={`card ${className || ''}`}>
        {children}
      </div>
  );

  const Button = ({ onClick, disabled, className, children }) => (
      <button
          onClick={onClick}
          disabled={disabled}
          className={`button ${className || ''}`}
      >
        {children}
      </button>
  );

  const Badge = ({ className, children }) => (
      <span className={`badge ${className || ''}`}>
      {children}
    </span>
  );

  // Icons (simplified versions)
  const Icon = ({ name, className }) => {
    const icons = {
      loader: <div className="icon-loader"></div>,
      camera: <div className="icon-camera"></div>,
      power: <div className="icon-power"></div>,
      zap: <div className="icon-zap"></div>,
      logo: <img src="/logo_icon.svg" alt="ë°”ìš´ë”© ë°•ìŠ¤" className="icon-logo" style={{ width: '50px', height: '50px' }} />,
      logo2: <img src="/logo_icon.svg" alt="ë°”ìš´ë”© ë°•ìŠ¤" className="icon-logo" />
    };
    return <div className={`icon ${className || ''}`}>{icons[name]}</div>;
  };

  return (
      <div className="app-container">
        {/* Header */}
        <div className="header">
          <div className="header-content">
            <div className="logo-container">
              <div>
                <Icon name="logo" />
              </div>
              <div>
                <h1>D-Lab Flow</h1>
                <p className="subtitle">ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨</p>
              </div>
            </div>

            {/* Status Indicators */}
            <div className="status-indicators">
              <div className="confidence-slider-container">
                <label htmlFor="confidence-slider">ì‹ ë¢°ë„: {Math.round(confidenceThreshold * 100)}%</label>
                <input
                  id="confidence-slider"
                  type="range"
                  min="40"
                  max="90"
                  value={confidenceThreshold * 100}
                  onChange={(e) => {
                    confidenceThreshold = Number(e.target.value) / 100;
                  }}
                  className="confidence-slider"
                  disabled={!isModelLoaded || isModelLoading}
                />
              </div>
            </div>
          </div>
        </div>

        {/* Main Content */}
        <div className="main-content">
          {isModelLoading ? (
              <Card className="loading-card">
                <div className="loading-spinner">
                  <Icon name="loader" />
                </div>
                <h2>AI ëª¨ë¸ ë¡œë”© ì¤‘...</h2>
              </Card>
          ) : errorMessage ? (
              <Card className="error-card">
                <div className="error-icon">
                  <Icon name="power" />
                </div>
                <h2>ì˜¤ë¥˜ ë°œìƒ</h2>
                <p>{errorMessage}</p>
                <Button
                    onClick={() => window.location.reload()}
                    className="start-button"
                    style={{ marginTop: '1rem', background: 'var(--danger-color)' }}
                >
                  ë‹¤ì‹œ ì‹œë„
                </Button>
              </Card>
          ) : !isDetecting ? (
              <Card className="start-card">
                <div>
                  <Icon name="logo2" />
                </div>
                <h2>D-Lab Flow ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨</h2>
                <p>ì¹´ë©”ë¼ ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”</p>
                <Button
                    onClick={startCamera}
                    disabled={!isModelLoaded}
                    className="start-button"
                >
                  <Icon name="camera" />
                  ì¹´ë©”ë¼ ì‹œì‘
                </Button>
              </Card>
          ) : (
              <div className="camera-view">
                {/* Camera View */}
                <div className="camera-container">
                  <Webcam
                      ref={webcamRef}
                      audio={false}
                      screenshotFormat="image/jpeg"
                      videoConstraints={{
                        facingMode: "environment", // í›„ë©´ ì¹´ë©”ë¼
                        width: { ideal: 960, min: 640 }, // ì ì ˆí•œ í•´ìƒë„ë¡œ ì¡°ì •
                        height: { ideal: 540, min: 480 },
                        frameRate: { ideal: 24, max: 30 }, // í”„ë ˆì„ ë ˆì´íŠ¸ ì†Œí­ ê°ì†Œ
                        aspectRatio: 16/9 // ì™€ì´ë“œìŠ¤í¬ë¦° ë¹„ìœ¨ ìœ ì§€
                      }}
                      style={{
                        position: 'absolute',
                        width: '100%',
                        height: '100%',
                        objectFit: 'cover',
                        zIndex: 1, // ìº”ë²„ìŠ¤ë³´ë‹¤ ë‚®ì€ z-indexë¡œ ë°°ê²½ìœ¼ë¡œ í‘œì‹œ
                        left: 0,
                        top: 0,
                        borderRadius: 'inherit' // ë¶€ëª¨ ìš”ì†Œì˜ ë‘¥ê·¼ ëª¨ì„œë¦¬ ìƒì†
                      }}
                      onUserMedia={(stream) => {
                        if (debugMode) {
                          console.log("Camera stream obtained successfully");
                          console.log("Stream settings:", stream.getVideoTracks()[0].getSettings());
                        }
                        streamRef.current = stream;

                        // ìº”ë²„ìŠ¤ ì •ë³´ í™•ì¸ (ë””ë²„ê¹…ìš©)
                        if (debugMode) {
                          const canvas = canvasRef.current;
                          if (canvas) {
                            console.log("Canvas ready:", canvas.width, canvas.height);
                          }
                        }
                      }}
                      onUserMediaError={(error) => {
                        console.error("Camera access error:", error);
                        let errorMsg = 'ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜';

                        if (error.name === 'NotAllowedError') {
                          errorMsg = 'ì¹´ë©”ë¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
                        } else if (error.name === 'NotFoundError') {
                          errorMsg = 'ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
                        } else if (error.name === 'NotSupportedError') {
                          errorMsg = 'HTTPS ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.';
                        }

                        setErrorMessage(errorMsg);
                        setIsDetecting(false);
                      }}
                  />
                  <canvas
                      ref={canvasRef}
                      className="detection-canvas"
                      style={{
                        position: 'absolute',
                        top: 0,
                        left: 0,
                        width: '100%',
                        height: '100%',
                        zIndex: 2, // ì›¹ìº ë³´ë‹¤ ë†’ì€ z-indexë¡œ íƒì§€ ê²°ê³¼ë§Œ í‘œì‹œ
                        objectFit: 'cover',
                        borderRadius: 'inherit', // ë¶€ëª¨ ìš”ì†Œì˜ ë‘¥ê·¼ ëª¨ì„œë¦¬ ìƒì†
                        touchAction: 'none', // í„°ì¹˜ ì´ë²¤íŠ¸ ë°©ì§€
                        pointerEvents: 'none' // ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ í†µê³¼ì‹œì¼œ ì•„ë˜ ìš”ì†Œì™€ ìƒí˜¸ì‘ìš© ê°€ëŠ¥í•˜ê²Œ í•¨
                      }}
                  />

                  {/* Controls Overlay */}
                  <div className="camera-controls">
                    <Button
                        onClick={stopCamera}
                        className="stop-button"
                        style={{
                          boxShadow: '0 4px 12px rgba(0, 0, 0, 0.3)', // ë” ê°•í•œ ê·¸ë¦¼ì
                          background: 'rgba(239, 68, 68, 0.25)', // ë” ì§„í•œ ë°°ê²½ìƒ‰
                          border: '2px solid rgba(239, 68, 68, 0.5)', // ë” ëˆˆì— ë„ëŠ” í…Œë‘ë¦¬
                          color: '#ef4444', // ë” ë°ì€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ
                          fontWeight: 'bold'
                        }}
                    >
                      <Icon name="power" />
                      ì¹´ë©”ë¼ ì¤‘ì§€
                    </Button>
                  </div>
                </div>

                {/* Detection Info - Always show the card, even when empty */}
                <Card className="detections-card">
                  <h3>
                    {detections.length > 0
                        ? `íƒì§€ëœ ê°ì²´ (${detections.length})`
                      : 'ê°ì²´ë¥¼ ì¹´ë©”ë¼ì— ë¹„ì¶°ë³´ì„¸ìš”'}
                  </h3>
                  {detections.length > 0 ? (
                      <div className="detection-badges">
                        {detections.map((detection, index) => (
                            <Badge
                                key={index}
                                className="detection-badge"
                                style={{
                                  // í´ë˜ìŠ¤ì— ë”°ë¼ ë‹¤ë¥¸ ìƒ‰ìƒ ì ìš©
                                  backgroundColor: `rgba(${(index * 50) % 255}, ${(index * 120) % 255}, ${(index * 180) % 255}, 0.15)`,
                                  borderColor: `rgba(${(index * 50) % 255}, ${(index * 120) % 255}, ${(index * 180) % 255}, 0.4)`
                                }}
                            >
                              {detection.class} ({Math.round(detection.confidence * 100)}%)
                            </Badge>
                        ))}
                      </div>
                  ) : isDetecting ? (
                      <div style={{ textAlign: 'center', marginTop: '0.5rem' }}>
                        <p style={{ color: 'var(--text-secondary)' }}>
                          íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤
                        </p>
                        <p style={{ color: 'var(--primary-color)', fontSize: '0.85rem', marginTop: '0.5rem' }}>
                          í˜„ì¬ ì‹ ë¢°ë„ ê¸°ì¤€: {Math.round(confidenceThreshold * 100)}% ì´ìƒ
                        </p>
                        <p style={{ color: 'var(--text-secondary)', fontSize: '0.85rem', marginTop: '0.5rem' }}>
                          ì¹´ë©”ë¼ì— ê°ì²´ë¥¼ ë¹„ì¶”ê±°ë‚˜ ì‹ ë¢°ë„ ì„¤ì •ì„ ì¡°ì •í•´ë³´ì„¸ìš”
                        </p>
                      </div>
                  ) : (
                      <p style={{ color: 'var(--text-secondary)', marginTop: '0.5rem' }}>
                        ì¹´ë©”ë¼ì— ê°ì²´ë¥¼ ë¹„ì¶”ë©´ ì—¬ê¸°ì— íƒì§€ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤
                      </p>
                  )}
                </Card>
              </div>
          )}
        </div>

        {/* Footer Info */}
        <div className="footer">
          <p>ğŸ’¡ D-Lab Flowì—ì„œ ìƒì„±í•œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨</p>
        </div>
      </div>
  );
}

export default App
