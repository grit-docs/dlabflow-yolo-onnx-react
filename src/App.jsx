/**
 * D-Lab Flow ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨
 *
 * ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ YOLOv5 ëª¨ë¸ë¡œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
 * ë¸Œë¼ìš°ì €ì—ì„œ ì™„ì „íˆ ë™ì‘í•˜ë©° ì‚¬ìš©ìì˜ ì¹´ë©”ë¼ë¥¼ í†µí•´ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ë°”ìš´ë”© ë°•ìŠ¤ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
 */
import { useState, useRef, useEffect, useCallback } from 'react'
import Webcam from 'react-webcam'
import * as ort from 'onnxruntime-web'
import './App.css'

// ì „ì—­ ë³€ìˆ˜ë¡œ ì •ì˜ (ìµœì†Œê°’ 0.4ë¡œ ì„¤ì •)
let confidenceThreshold = 0.4;

function App() {
  // Refs
  const webcamRef = useRef(null);
  const canvasRef = useRef(null);
  const sessionRef = useRef(null);
  const animationRef = useRef(null);
  const streamRef = useRef(null);

  // State variables
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [isModelLoading, setIsModelLoading] = useState(true);
  const [classes, setClasses] = useState([]);
  const [isDetecting, setIsDetecting] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  const [detections, setDetections] = useState([]);
  const [debugMode] = useState(true);


  useEffect(() => {
    async function loadModel() {
      try {
        setIsModelLoading(true);
        const classesResponse = await fetch('/models/classes.json');
        const classesData = await classesResponse.json();
        setClasses(classesData);
        const modelPath = '/models/model.onnx';

        // ONNX Runtime ìµœì í™” ì˜µì…˜ ì¶”ê°€
        const session = await ort.InferenceSession.create(modelPath, {
          executionProviders: ['webgl', 'cpu'], // WebGL ìš°ì„ , CPU ëŒ€ì²´
          graphOptimizationLevel: 'all', // ê·¸ë˜í”„ ìµœì í™”
          enableCpuMemArena: false, // ë©”ëª¨ë¦¬ ì•„ë ˆë‚˜ ë¹„í™œì„±í™” (ëª¨ë°”ì¼ì—ì„œ ë” ë‚˜ìŒ)
          enableMemPattern: false, // ë©”ëª¨ë¦¬ íŒ¨í„´ ë¹„í™œì„±í™”
        });

        sessionRef.current = session;
        setIsModelLoaded(true);
        setIsModelLoading(false);
      } catch (error) {
        console.error('Error loading model:', error);
        setErrorMessage('ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜. public/models ë””ë ‰í† ë¦¬ì— model.onnx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.');
        setIsModelLoading(false);
      }
    }
    loadModel();
    return () => {
      if (animationRef.current) cancelAnimationFrame(animationRef.current);
      if (streamRef.current) streamRef.current.getTracks().forEach(track => track.stop());
    };
  }, []);


  const startCamera = async () => {
    try {
      setIsDetecting(true);
    } catch (error) {
      console.error('Camera access failed:', error);
      setErrorMessage(`ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${error.message || 'ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.'}`);
    }
  };

  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
      animationRef.current = null;
    }
    setIsDetecting(false);
    setDetections([]);
  };

  const detectObjects = useCallback(async () => {
    if (!webcamRef.current || !canvasRef.current || !sessionRef.current || !isDetecting) return;

    const video = webcamRef.current.video;
    const canvas = canvasRef.current;
    if (!video || video.readyState !== 4 || video.paused) {
      if (isDetecting) animationRef.current = requestAnimationFrame(detectObjects);
      return;
    }

    try {
      const ctx = canvas.getContext('2d');
      const videoWidth = video.videoWidth;
      const videoHeight = video.videoHeight;
      canvas.width = videoWidth;
      canvas.height = videoHeight;

      setIsProcessing(true);
      try {
        // ì¶”ë¡ ìš© ìº”ë²„ìŠ¤ ìƒì„± (ëª¨ë°”ì¼ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ìŠ¤ì¼€ì¼ ì¡°ì •)
        const scaleCanvas = document.createElement('canvas');
        const scaleFactor = 1.0; // ëª¨ë°”ì¼ ì„±ëŠ¥ì„ ìœ„í•´ ì›ë³¸ í¬ê¸°ë¡œ ìœ ì§€
        scaleCanvas.width = Math.floor(videoWidth * scaleFactor);
        scaleCanvas.height = Math.floor(videoHeight * scaleFactor);
        const scaleCtx = scaleCanvas.getContext('2d');
        scaleCtx.drawImage(video, 0, 0, scaleCanvas.width, scaleCanvas.height);

        const imageData = scaleCtx.getImageData(0, 0, scaleCanvas.width, scaleCanvas.height);
        const [input, imgWidth, imgHeight] = await prepareInput(imageData);
        const feeds = { images: input };
        const results = await sessionRef.current.run(feeds);
        const output = results[Object.keys(results)[0]];
        const currentDetections = processDetections(output.data, output.dims, imgWidth, imgHeight, videoWidth, videoHeight);

        // íƒì§€ëœ ê°ì²´ë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ì´ ë°”ë¡œ ì„¤ì •
        setDetections(currentDetections);

        // í˜„ì¬ íƒì§€ëœ ê°ì²´ë“¤ë§Œ ë°”ë¡œ ê·¸ë¦¬ê¸°
        drawBoundingBoxes(currentDetections, ctx, canvas.width, canvas.height);
      } catch (error) {
        console.error('Detection processing error:', error);
      } finally {
        setIsProcessing(false);
      }
    } catch (error) {
      console.error('Canvas operation error:', error);
    }

    if (isDetecting && !isProcessing) {
      animationRef.current = setTimeout(() => {
        detectObjects();
      }, 150); // ì´ˆë‹¹ ì•½ 6-7íšŒ, ì ì ˆí•œ ê· í˜•ì 
    }

  }, [isDetecting, classes]);

  // Process detections from model output
  const processDetections = (data, dims, imgWidth, imgHeight, canvasWidth, canvasHeight) => {
    const numDetections = dims[1];

    // ëª¨ë¸ ì…ë ¥ í¬ê¸° (YOLOv5ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 640x640 ì…ë ¥ì„ ì‚¬ìš©)
    const modelWidth = 640;
    const modelHeight = 640;

    // ìº”ë²„ìŠ¤ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì • (ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ì—ì„œ ì¤‘ìš”)
    const scaleX = canvasWidth / modelWidth;
    const scaleY = canvasHeight / modelHeight;

    if (debugMode) {
      console.log(`Detection scaling: ${scaleX}x${scaleY}, Canvas: ${canvasWidth}x${canvasHeight}`);
      console.log(`ì¶”ë¡  ì‹œì‘: ì´ ${numDetections}ê°œì˜ ê°ì²´ í›„ë³´ ì²˜ë¦¬ ì¤‘...`);
    }

    const rawDetections = [];
    // í´ë˜ìŠ¤ë³„ íƒì§€ ì¹´ìš´í„° ì´ˆê¸°í™”
    const classDetections = {};

    for (let i = 0; i < numDetections; i++) {
      // Get detection data (each detection has 6 values)
      const base = i * 85; // ğŸ”„ 6 â†’ 85ë¡œ ë³€ê²½

      const objectness = 1 / (1 + Math.exp(-data[base + 4]));
      let maxClassProb = 0;
      let classIndex = 0;
      for (let j = 5; j < 85; j++) {
        const prob = 1 / (1 + Math.exp(-data[base + j]));
        if (prob > maxClassProb) {
          maxClassProb = prob;
          classIndex = j - 5;
        }
      }
      const confidence = objectness * maxClassProb;

      const className = classes[classIndex] || `í´ë˜ìŠ¤ ${classIndex}`;

      // Filter by confidence threshold
      if (confidence > confidenceThreshold) {
        // Extract bounding box coordinates
        const x = data[base] * scaleX;
        const y = data[base + 1] * scaleY;
        const width = data[base + 2] * scaleX;
        const height = data[base + 3] * scaleY;

        // Track detections by class
        if (!classDetections[className]) {
          classDetections[className] = {
            count: 0,
            confidenceSum: 0,
            highestConfidence: 0
          };
        }
        classDetections[className].count++;
        classDetections[className].confidenceSum += confidence;
        classDetections[className].highestConfidence = Math.max(classDetections[className].highestConfidence, confidence);

        // Log individual detection with high confidence (only in debug mode)
        if (debugMode) {
          console.log(`íƒì§€ëœ ê°ì²´: ${className}, ì¸ì‹ë¥ : ${(confidence * 100).toFixed(2)}%, ìœ„ì¹˜: [x=${Math.round(x)}, y=${Math.round(y)}]`);
        }

        rawDetections.push({
          bbox: [x - width/2, y - height/2, width, height],
          class: className,
          confidence: confidence,
          classIndex: classIndex
        });
      }
    }

    // Apply Non-Maximum Suppression to filter out overlapping detections
    const detections = applyNonMaxSuppression(rawDetections, 0.3); // 0.3 is the IoU threshold (lower value = more aggressive filtering)

    // ì¶”ë¡  ê²°ê³¼ ìš”ì•½ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ)
    if (debugMode) {
      if (Object.keys(classDetections).length > 0) {
        console.log('======== ì¶”ë¡  ê²°ê³¼ ìš”ì•½ ========');
        console.log(`ì´ íƒì§€ëœ ê°ì²´ ìˆ˜: ${rawDetections.length}ê°œ (NMS ì ìš© ì „), ${detections.length}ê°œ (NMS ì ìš© í›„)`);

        // í´ë˜ìŠ¤ë³„ íƒì§€ ê²°ê³¼ ë° ì¸ì‹ë¥  ì¶œë ¥
        Object.keys(classDetections).forEach(className => {
          const stats = classDetections[className];
          const avgConfidence = stats.confidenceSum / stats.count;
          console.log(`í´ë˜ìŠ¤: ${className}, íƒì§€ ìˆ˜: ${stats.count}ê°œ, í‰ê·  ì¸ì‹ë¥ : ${(avgConfidence * 100).toFixed(2)}%, ìµœê³  ì¸ì‹ë¥ : ${(stats.highestConfidence * 100).toFixed(2)}%`);
        });
        console.log('===============================');
      } else {
        console.log('íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.');
      }
    }

    return detections;
  };

  // Calculate Intersection over Union (IoU) between two bounding boxes
  const calculateIoU = (box1, box2) => {
    // box format: [x, y, width, height] where x,y is the top-left corner
    const [x1, y1, w1, h1] = box1;
    const [x2, y2, w2, h2] = box2;

    // Calculate coordinates of the intersection rectangle
    const xLeft = Math.max(x1, x2);
    const yTop = Math.max(y1, y2);
    const xRight = Math.min(x1 + w1, x2 + w2);
    const yBottom = Math.min(y1 + h1, y2 + h2);

    // Check if there is an intersection
    if (xRight < xLeft || yBottom < yTop) {
      return 0;
    }

    // Calculate intersection area
    const intersectionArea = (xRight - xLeft) * (yBottom - yTop);

    // Calculate union area
    const box1Area = w1 * h1;
    const box2Area = w2 * h2;
    const unionArea = box1Area + box2Area - intersectionArea;

    // Calculate IoU
    return intersectionArea / unionArea;
  };

  // Apply Non-Maximum Suppression to filter out overlapping detections
  const applyNonMaxSuppression = (detections, iouThreshold) => {
    if (detections.length === 0) {
      return [];
    }

    // Sort detections by confidence score (highest first)
    const sortedDetections = [...detections].sort((a, b) => b.confidence - a.confidence);

    const selectedDetections = [];
    const remainingDetections = [...sortedDetections];

    // Process all detections
    while (remainingDetections.length > 0) {
      // Select the detection with highest confidence
      const currentDetection = remainingDetections.shift();
      selectedDetections.push(currentDetection);

      // Filter out detections that have high overlap with the current detection
      // and are of the same class
      let i = 0;
      while (i < remainingDetections.length) {
        // Only apply NMS to detections of the same class
        if (remainingDetections[i].classIndex === currentDetection.classIndex) {
          const iou = calculateIoU(currentDetection.bbox, remainingDetections[i].bbox);

          // If IoU is above threshold, remove this detection
          if (iou > iouThreshold) {
            remainingDetections.splice(i, 1);
          } else {
            i++;
          }
        } else {
          i++;
        }
      }
    }

    return selectedDetections;
  };

  // Prepare input tensor for the model
  const prepareInput = async (imageData) => {
    // YOLOv5 expects input in format [batch, channels, height, width]
    const imgWidth = imageData.width;
    const imgHeight = imageData.height;

    // YOLOv5 models typically expect 640x640 input
    const modelWidth = 640;
    const modelHeight = 640;

    // Create a temporary canvas for the source image data
    const sourceCanvas = document.createElement('canvas');
    sourceCanvas.width = imgWidth;
    sourceCanvas.height = imgHeight;
    const sourceCtx = sourceCanvas.getContext('2d');
    sourceCtx.putImageData(imageData, 0, 0);

    // Create a temporary canvas for resizing
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = modelWidth;
    tempCanvas.height = modelHeight;
    const tempCtx = tempCanvas.getContext('2d');

    // Draw and resize the image
    tempCtx.drawImage(
        sourceCanvas,
        0, 0, imgWidth, imgHeight,
        0, 0, modelWidth, modelHeight
    );

    // Get the resized image data
    const resizedImageData = tempCtx.getImageData(0, 0, modelWidth, modelHeight);
    const pixels = resizedImageData.data;

    // Prepare the input tensor (NCHW format)
    // YOLOv5 expects RGB values normalized to [0, 1]
    const inputTensor = new Float32Array(modelWidth * modelHeight * 3);
    let inputIndex = 0;

    // Convert from RGBA to RGB and normalize
    for (let c = 0; c < 3; c++) {
      for (let h = 0; h < modelHeight; h++) {
        for (let w = 0; w < modelWidth; w++) {
          const pixelIndex = (h * modelWidth + w) * 4; // RGBA has 4 channels
          inputTensor[inputIndex++] = pixels[pixelIndex + c] / 255.0;
        }
      }
    }

    // Create the ONNX tensor
    const tensor = new ort.Tensor('float32', inputTensor, [1, 3, modelHeight, modelWidth]);

    return [tensor, imgWidth, imgHeight];
  };

  // Draw bounding boxes on the canvas
  const drawBoundingBoxes = (detections, ctx, canvasWidth, canvasHeight) => {
    try {
      // ìº”ë²„ìŠ¤ ìƒíƒœ ì €ì¥
      ctx.save();

      // ê¸°ë³¸ ìº”ë²„ìŠ¤ ì„¤ì • (ëª¨ë°”ì¼ í˜¸í™˜ì„± ìœ„í•´ ê°„ì†Œí™”)
      ctx.imageSmoothingEnabled = true;
      ctx.imageSmoothingQuality = 'medium'; // highì—ì„œ mediumìœ¼ë¡œ ì¡°ì •

      // ìº”ë²„ìŠ¤ í´ë¦¬ì–´ - ì´ì œ ë¹„ë””ì˜¤ë¥¼ ê·¸ë¦¬ì§€ ì•Šê³  íƒì§€ ê²°ê³¼ë§Œ í‘œì‹œ
      ctx.clearRect(0, 0, canvasWidth, canvasHeight);

      // ëª¨ë“  íƒì§€ëœ ê°ì²´ ì‚¬ìš© (í•„í„°ë§ ì—†ìŒ)
      const recentDetections = detections;

      // ë¹„ë””ì˜¤ í”„ë ˆì„ì€ ë” ì´ìƒ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ì§€ ì•ŠìŒ (Webcam ì»´í¬ë„ŒíŠ¸ê°€ ë°°ê²½ìœ¼ë¡œ í‘œì‹œë¨)

      if (debugMode && webcamRef.current && webcamRef.current.video) {
        const video = webcamRef.current.video;
        if (video.readyState === 4) {
          // Log video dimensions only in debug mode
          console.log(`Video dimensions: ${video.videoWidth}x${video.videoHeight}`);
        }
      }

      if (debugMode) {
        console.log(`Drawing ${recentDetections.length} bounding boxes - Canvas dimensions: ${canvasWidth}x${canvasHeight}`);
      }

      // ìµœì¢… í™”ë©´ì— í‘œì‹œë˜ëŠ” íƒì§€ ê²°ê³¼ ìš”ì•½ (ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ)
      if (debugMode && recentDetections.length > 0) {
        console.log('======== í™”ë©´ í‘œì‹œ íƒì§€ ê²°ê³¼ ========');
        // í´ë˜ìŠ¤ë³„ í†µê³„ ê³„ì‚°ì„ ìœ„í•œ ê°ì²´
        const finalClassStats = {};

        recentDetections.forEach(detection => {
          const className = detection.class;
          if (!finalClassStats[className]) {
            finalClassStats[className] = {
              count: 0,
              confidenceSum: 0
            };
          }
          finalClassStats[className].count++;
          finalClassStats[className].confidenceSum += detection.confidence;
        });

        // í´ë˜ìŠ¤ë³„ í†µê³„ ì¶œë ¥
        Object.keys(finalClassStats).forEach(className => {
          const stats = finalClassStats[className];
          const avgConfidence = stats.confidenceSum / stats.count;
          console.log(`í´ë˜ìŠ¤: ${className}, ê°œìˆ˜: ${stats.count}ê°œ, í‰ê·  ì¸ì‹ë¥ : ${(avgConfidence * 100).toFixed(2)}%`);
        });
        console.log('==================================');
      }

      // Set drawing styles
      ctx.lineWidth = 1; // Reduced line width as requested
      ctx.font = 'bold 18px Arial'; // Made font bold for better visibility
      ctx.textBaseline = 'top';

      // ìº”ë²„ìŠ¤ ì˜¤ë²„ë ˆì´ ë°°ê²½ì„ ë” íˆ¬ëª…í•˜ê²Œ ì¡°ì •
      // ì‹¤ì œ ì¹´ë©”ë¼ ì˜ìƒì´ ë” ì˜ ë³´ì´ë„ë¡ í•¨
      ctx.fillStyle = 'rgba(0, 0, 0, 0.0)';
      ctx.fillRect(0, 0, canvasWidth, canvasHeight);

      // Draw each filtered detection
      recentDetections.forEach((detection, i) => {
        const [drawX, drawY, width, height] = detection.bbox;
        const className = detection.class;
        const confidence = detection.confidence;
        const classIndex = detection.classIndex;

        // Log the detection information with more details in Korean (only in debug mode)
        if (debugMode) {
          console.log(`ìµœì¢… íƒì§€ #${i+1}: í´ë˜ìŠ¤=${className}, ì¸ì‹ë¥ =${(confidence * 100).toFixed(2)}%, ìœ„ì¹˜=[x=${Math.round(drawX)}, y=${Math.round(drawY)}, ë„ˆë¹„=${Math.round(width)}, ë†’ì´=${Math.round(height)}]`);
        }

        // Generate random color based on class index
        const hue = (classIndex * 137) % 360; // Use prime number for better distribution

        // ë” ì–‡ì€ í…Œë‘ë¦¬ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        ctx.strokeStyle = `hsl(${hue}, 100%, 50%)`;
        ctx.lineWidth = 2; // ì¤„ì–´ë“  ì„  ë‘ê»˜ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ë” ê¹”ë”í•˜ê²Œ í‘œì‹œ

        // ë” íˆ¬ëª…í•œ ë‚´ë¶€ ìƒ‰ìƒ ì‚¬ìš©
        ctx.fillStyle = `hsla(${hue}, 100%, 40%, 0.15)`; // ë‚®ì€ ë¶ˆíˆ¬ëª…ë„ë¡œ ë‚´ë¶€ ìƒ‰ìƒ ì˜…ê²Œ í‘œì‹œ

        // Draw bounding box with more visible style
        ctx.beginPath();
        ctx.rect(drawX, drawY, width, height);
        ctx.fill();
        ctx.stroke();

        // ë¼ë²¨ ë°°ê²½ë„ ì•½ê°„ íˆ¬ëª…í•˜ê²Œ ì¡°ì •
        const label = `${className} ${Math.round(confidence * 100)}%`;
        const textMetrics = ctx.measureText(label);
        const textHeight = 28; // ë¼ë²¨ ë†’ì´ ìœ ì§€
        ctx.fillStyle = `hsla(${hue}, 100%, 50%, 0.7)`; // ì•½ê°„ íˆ¬ëª…í•˜ê²Œ ì¡°ì •

        // Calculate label position
        const labelX = drawX;
        const labelY = drawY - textHeight;

        ctx.fillRect(
            labelX,
            labelY,
            textMetrics.width + 10,
            textHeight
        );

        // ëª¨ë°”ì¼ì—ì„œ ë” ì˜ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
        // í…ìŠ¤íŠ¸ì— ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€
        ctx.shadowColor = 'black';
        ctx.shadowBlur = 3;
        ctx.shadowOffsetX = 1;
        ctx.shadowOffsetY = 1;

        // í°ìƒ‰ êµµì€ í…ìŠ¤íŠ¸
        ctx.fillStyle = 'white';
        ctx.font = 'bold 18px Arial'; // êµµì€ ê¸€ì”¨ì²´
        ctx.fillText(
            label,
            labelX + 5,
            labelY + 5
        );

        // ê·¸ë¦¼ì íš¨ê³¼ ì œê±°
        ctx.shadowColor = 'transparent';

        // í…ìŠ¤íŠ¸ ì™¸ê³½ì„  (ì„ íƒì )
        ctx.strokeStyle = 'black';
        ctx.lineWidth = 1;
        ctx.strokeText(
            label,
            labelX + 5,
            labelY + 5
        );
      });

      // Restore the canvas state
      ctx.restore();

    } catch (error) {
      console.error("Error in drawBoundingBoxes:", error);
    }
  };

  // Inline UI components
  const Card = ({ className, children }) => (
      <div className={`card ${className || ''}`}>
        {children}
      </div>
  );

  const Button = ({ onClick, disabled, className, children }) => (
      <button
          onClick={onClick}
          disabled={disabled}
          className={`button ${className || ''}`}
      >
        {children}
      </button>
  );

  const Badge = ({ className, children }) => (
      <span className={`badge ${className || ''}`}>
      {children}
    </span>
  );

  // Icons (simplified versions)
  const Icon = ({ name, className }) => {
    const icons = {
      loader: <div className="icon-loader"></div>,
      camera: <div className="icon-camera"></div>,
      power: <div className="icon-power"></div>,
      zap: <div className="icon-zap"></div>,
      logo: <img src="/logo_icon.svg" alt="ë°”ìš´ë”© ë°•ìŠ¤" className="icon-logo" style={{ width: '50px', height: '50px' }} />,
      logo2: <img src="/logo_icon.svg" alt="ë°”ìš´ë”© ë°•ìŠ¤" className="icon-logo" />
    };
    return <div className={`icon ${className || ''}`}>{icons[name]}</div>;
  };

  return (
      <div className="app-container">
        {/* Header */}
        <div className="header">
          <div className="header-content">
            <div className="logo-container">
              <div>
                <Icon name="logo" />
              </div>
              <div>
                <h1>D-Lab Flow</h1>
                <p className="subtitle">ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨</p>
              </div>
            </div>

            {/* Status Indicators */}
            <div className="status-indicators">
              <div className="confidence-slider-container">
                <label htmlFor="confidence-slider">ì‹ ë¢°ë„: {Math.round(confidenceThreshold * 100)}%</label>
                <input
                  id="confidence-slider"
                  type="range"
                  min="40"
                  max="90"
                  value={confidenceThreshold * 100}
                  onChange={(e) => {
                    confidenceThreshold = Number(e.target.value) / 100;
                    // ê°•ì œ ë¦¬ë Œë”ë§ì„ ìœ„í•œ ë”ë¯¸ ìƒíƒœ ì—…ë°ì´íŠ¸
                    setIsProcessing(prev => !prev);
                    setIsProcessing(prev => !prev);
                  }}
                  className="confidence-slider"
                  disabled={!isModelLoaded || isModelLoading}
                />
              </div>
              {isProcessing && (
                  <Badge className="processing-badge">
                    <Icon name="zap" />
                    ì²˜ë¦¬ ì¤‘
                  </Badge>
              )}
            </div>
          </div>
        </div>

        {/* Main Content */}
        <div className="main-content">
          {isModelLoading ? (
              <Card className="loading-card">
                <div className="loading-spinner">
                  <Icon name="loader" />
                </div>
                <h2>AI ëª¨ë¸ ë¡œë”© ì¤‘...</h2>
              </Card>
          ) : errorMessage ? (
              <Card className="error-card">
                <div className="error-icon">
                  <Icon name="power" />
                </div>
                <h2>ì˜¤ë¥˜ ë°œìƒ</h2>
                <p>{errorMessage}</p>
                <Button
                    onClick={() => window.location.reload()}
                    className="start-button"
                    style={{ marginTop: '1rem', background: 'var(--danger-color)' }}
                >
                  ë‹¤ì‹œ ì‹œë„
                </Button>
              </Card>
          ) : !isDetecting ? (
              <Card className="start-card">
                <div>
                  <Icon name="logo2" />
                </div>
                <h2>D-Lab Flow ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨</h2>
                <p>ì¹´ë©”ë¼ ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”</p>
                <Button
                    onClick={startCamera}
                    disabled={!isModelLoaded}
                    className="start-button"
                >
                  <Icon name="camera" />
                  ì¹´ë©”ë¼ ì‹œì‘
                </Button>
              </Card>
          ) : (
              <div className="camera-view">
                {/* Camera View */}
                <div className="camera-container">
                  <Webcam
                      ref={webcamRef}
                      audio={false}
                      screenshotFormat="image/jpeg"
                      videoConstraints={{
                        facingMode: "environment", // í›„ë©´ ì¹´ë©”ë¼
                        width: { ideal: 960, min: 640 }, // ì ì ˆí•œ í•´ìƒë„ë¡œ ì¡°ì •
                        height: { ideal: 540, min: 480 },
                        frameRate: { ideal: 24, max: 30 }, // í”„ë ˆì„ ë ˆì´íŠ¸ ì†Œí­ ê°ì†Œ
                        aspectRatio: 16/9 // ì™€ì´ë“œìŠ¤í¬ë¦° ë¹„ìœ¨ ìœ ì§€
                      }}
                      style={{
                        position: 'absolute',
                        width: '100%',
                        height: '100%',
                        objectFit: 'cover',
                        zIndex: 1, // ìº”ë²„ìŠ¤ë³´ë‹¤ ë‚®ì€ z-indexë¡œ ë°°ê²½ìœ¼ë¡œ í‘œì‹œ
                        left: 0,
                        top: 0,
                        borderRadius: 'inherit' // ë¶€ëª¨ ìš”ì†Œì˜ ë‘¥ê·¼ ëª¨ì„œë¦¬ ìƒì†
                      }}
                      onUserMedia={(stream) => {
                        if (debugMode) {
                          console.log("Camera stream obtained successfully");
                          console.log("Stream settings:", stream.getVideoTracks()[0].getSettings());
                        }
                        streamRef.current = stream;

                        // ìº”ë²„ìŠ¤ ì •ë³´ í™•ì¸ (ë””ë²„ê¹…ìš©)
                        if (debugMode) {
                          const canvas = canvasRef.current;
                          if (canvas) {
                            console.log("Canvas ready:", canvas.width, canvas.height);
                          }
                        }

                        // ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ íšë“ í›„ ì¦‰ì‹œ íƒì§€ ì‹œì‘ (requestAnimationFrame ì‚¬ìš©)
                        requestAnimationFrame(detectObjects);
                      }}
                      onUserMediaError={(error) => {
                        console.error("Camera access error:", error);
                        let errorMsg = 'ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜';

                        if (error.name === 'NotAllowedError') {
                          errorMsg = 'ì¹´ë©”ë¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
                        } else if (error.name === 'NotFoundError') {
                          errorMsg = 'ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
                        } else if (error.name === 'NotSupportedError') {
                          errorMsg = 'HTTPS ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.';
                        }

                        setErrorMessage(errorMsg);
                        setIsDetecting(false);
                      }}
                  />
                  <canvas
                      ref={canvasRef}
                      className="detection-canvas"
                      style={{
                        position: 'absolute',
                        top: 0,
                        left: 0,
                        width: '100%',
                        height: '100%',
                        zIndex: 2, // ì›¹ìº ë³´ë‹¤ ë†’ì€ z-indexë¡œ íƒì§€ ê²°ê³¼ë§Œ í‘œì‹œ
                        objectFit: 'cover',
                        borderRadius: 'inherit', // ë¶€ëª¨ ìš”ì†Œì˜ ë‘¥ê·¼ ëª¨ì„œë¦¬ ìƒì†
                        touchAction: 'none', // í„°ì¹˜ ì´ë²¤íŠ¸ ë°©ì§€
                        pointerEvents: 'none' // ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ í†µê³¼ì‹œì¼œ ì•„ë˜ ìš”ì†Œì™€ ìƒí˜¸ì‘ìš© ê°€ëŠ¥í•˜ê²Œ í•¨
                      }}
                  />

                  {/* Controls Overlay */}
                  <div className="camera-controls">
                    <Button
                        onClick={stopCamera}
                        className="stop-button"
                        style={{
                          boxShadow: '0 4px 12px rgba(0, 0, 0, 0.3)', // ë” ê°•í•œ ê·¸ë¦¼ì
                          background: 'rgba(239, 68, 68, 0.25)', // ë” ì§„í•œ ë°°ê²½ìƒ‰
                          border: '2px solid rgba(239, 68, 68, 0.5)', // ë” ëˆˆì— ë„ëŠ” í…Œë‘ë¦¬
                          color: '#ef4444', // ë” ë°ì€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ
                          fontWeight: 'bold'
                        }}
                    >
                      <Icon name="power" />
                      ì¹´ë©”ë¼ ì¤‘ì§€
                    </Button>
                  </div>
                </div>

                {/* Detection Info - Always show the card, even when empty */}
                <Card className="detections-card">
                  <h3>
                    {detections.length > 0
                        ? `íƒì§€ëœ ê°ì²´ (${detections.length})`
                      : 'ê°ì²´ë¥¼ ì¹´ë©”ë¼ì— ë¹„ì¶°ë³´ì„¸ìš”'}
                  </h3>
                  {detections.length > 0 ? (
                      <div className="detection-badges">
                        {detections.map((detection, index) => (
                            <Badge
                                key={index}
                                className="detection-badge"
                                style={{
                                  // í´ë˜ìŠ¤ì— ë”°ë¼ ë‹¤ë¥¸ ìƒ‰ìƒ ì ìš©
                                  backgroundColor: `rgba(${(index * 50) % 255}, ${(index * 120) % 255}, ${(index * 180) % 255}, 0.15)`,
                                  borderColor: `rgba(${(index * 50) % 255}, ${(index * 120) % 255}, ${(index * 180) % 255}, 0.4)`
                                }}
                            >
                              {detection.class} ({Math.round(detection.confidence * 100)}%)
                            </Badge>
                        ))}
                      </div>
                  ) : isDetecting ? (
                      <div style={{ textAlign: 'center', marginTop: '0.5rem' }}>
                        <p style={{ color: 'var(--text-secondary)' }}>
                          íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤
                        </p>
                        <p style={{ color: 'var(--primary-color)', fontSize: '0.85rem', marginTop: '0.5rem' }}>
                          í˜„ì¬ ì‹ ë¢°ë„ ê¸°ì¤€: {Math.round(confidenceThreshold * 100)}% ì´ìƒ
                        </p>
                        <p style={{ color: 'var(--text-secondary)', fontSize: '0.85rem', marginTop: '0.5rem' }}>
                          ì¹´ë©”ë¼ì— ê°ì²´ë¥¼ ë¹„ì¶”ê±°ë‚˜ ì‹ ë¢°ë„ ì„¤ì •ì„ ì¡°ì •í•´ë³´ì„¸ìš”
                        </p>
                      </div>
                  ) : (
                      <p style={{ color: 'var(--text-secondary)', marginTop: '0.5rem' }}>
                        ì¹´ë©”ë¼ì— ê°ì²´ë¥¼ ë¹„ì¶”ë©´ ì—¬ê¸°ì— íƒì§€ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤
                      </p>
                  )}
                </Card>
              </div>
          )}
        </div>

        {/* Footer Info */}
        <div className="footer">
          <p>ğŸ’¡ D-Lab Flowì—ì„œ ìƒì„±í•œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë°ëª¨</p>
        </div>
      </div>
  );
}

export default App
